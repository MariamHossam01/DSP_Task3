{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, the WAV files will be read and their features will be saved in the CSV files\n",
    "# As this is the most time consuming task, only enable it if you don't have the CSV files yet\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "MORE_TRAIN_CSV_FILE = \"more_train.csv\"\n",
    "MORE_TEST_CSV_FILE = \"more_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder recordings/close will be saved to train.csv\n",
      "The features of the files in the folder recordings/open will be saved to train.csv\n",
      "The features of the files in the folder recordings/open will be saved to test.csv\n",
      "CSV files are created\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "import chromaFeatures \n",
    "import librosa.display\n",
    "if(os.path.exists(TRAIN_CSV_FILE) and os.path.isfile(TRAIN_CSV_FILE)):\n",
    "    os.remove(TRAIN_CSV_FILE)\n",
    "if(os.path.exists(TEST_CSV_FILE) and os.path.isfile(TEST_CSV_FILE)):\n",
    "    os.remove(TEST_CSV_FILE)\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName,label):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate '\n",
    "    # header = 'filename '\n",
    "    for i in range(1, 21):\n",
    "        header += f'mfcc{i} '\n",
    "    header += 'label '\n",
    "    header = header.split()\n",
    "    if not os.path.exists(csvFileName):\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    else:\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "    genres = '1 2 3 4 5 6 7 8 9 0'.split()\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        # chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_stft = chromaFeatures.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append+=f' {label}'\n",
    "        writer.writerow(to_append.split())\n",
    "        # writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"recordings/close\", TRAIN_CSV_FILE,1)\n",
    "    extractWavFeatures(\"recordings/open\", TRAIN_CSV_FILE,0)\n",
    "    extractWavFeatures(\"recordings/open\", TEST_CSV_FILE,0)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melspec_mean_list=[]\n",
    "# melspec_var_list=[]\n",
    "# for i in range(1,16):\n",
    "#     y, sr = librosa.load(f'..\\\\data\\\\recordings\\\\Dina\\\\open\\\\h_open_({i}).wav', mono=True, duration=30)\n",
    "#     # this is the number of samples in a window per fft\n",
    "#     # n_fft = 2048\n",
    "#     # # The amount of samples we are shifting after each fft\n",
    "#     # hop_length = 512\n",
    "#     mel_signal = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "#     melspec_mean = np.mean(mel_signal)\n",
    "#     melspec_var = np.var(mel_signal)\n",
    "#     melspec_mean_list.append(melspec_mean)\n",
    "#     melspec_var_list.append(melspec_var)\n",
    "#     # print(f'mean{i}:{melspec_mean}')\n",
    "#     # print(f'var{i}:{melspec_var}')\n",
    "#     # spectrogram = np.abs(mel_signal)\n",
    "#     # power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "#     # librosa.display.specshow(power_to_db, sr=sr, x_axis='time', y_axis='mel', cmap='magma', hop_length=hop_length)\n",
    "# print(f'mean_max{max(melspec_mean_list)},mean_min:{min(melspec_mean_list)},mean_mean{np.mean(melspec_mean_list)}')\n",
    "# print(f'var_max{max(melspec_var_list)},var_min:{min(melspec_var_list)},var_mean{np.mean(melspec_var_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # melspec_mean_list=[]\n",
    "# # melspec_var_list=[]\n",
    "# # for i in range(1,16):\n",
    "# y, sr = librosa.load(f'..\\\\data\\\\recordings\\\\Mariam\\\\close\\\\b_close_(1).wav', mono=True, duration=30)\n",
    "# # this is the number of samples in a window per fft\n",
    "# # n_fft = 2048\n",
    "# # # The amount of samples we are shifting after each fft\n",
    "# # hop_length = 512\n",
    "# mel_signal = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "# melspec_mean = np.mean(mel_signal)\n",
    "# melspec_var = np.var(mel_signal)\n",
    "# melspec_mean_list.append(melspec_mean)\n",
    "# melspec_var_list.append(melspec_var)\n",
    "# # print(f'mean{i}:{melspec_mean}')\n",
    "# # print(f'var{i}:{melspec_var}')\n",
    "# spectrogram = np.abs(mel_signal)\n",
    "# power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "# librosa.display.specshow(power_to_db, sr=sr, x_axis='time', y_axis='mel', cmap='magma', hop_length=hop_length)\n",
    "# # print(f'mean_max{max(melspec_mean_list)},mean_min:{min(melspec_mean_list)},mean_mean{np.mean(melspec_mean_list)}')\n",
    "# # print(f'var_max{max(melspec_var_list)},var_min:{min(melspec_var_list)},var_mean{np.mean(melspec_var_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, sr = librosa.load('..\\\\recordings\\\\test\\\\close(13).wav', mono=True, duration=30)\n",
    "# mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "# mfcc\n",
    "# mfcc_list=[]\n",
    "# for e in mfcc:\n",
    "#             mfcc_list.append(e)\n",
    "# print(len(mfcc_list))\n",
    "# print(mfcc_list)\n",
    "# # mfcc.shape\n",
    "\n",
    "\n",
    "\n",
    "# import freature_ex as ex\n",
    "\n",
    "# mfcc=ex.get_mfcc(y,sr)\n",
    "# mfcc_list=[]\n",
    "# for e in mfcc:\n",
    "#             mfcc_list.append(e)\n",
    "# print(len(mfcc_list))\n",
    "# print(mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, sr = librosa.load('..\\\\recordings\\\\test\\\\close(13).wav', mono=True, duration=30)\n",
    "# op=np.mean(librosa.feature.chroma_stft(y=y,sr=sr))\n",
    "# op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromaFeatures as ft \n",
    "# op= np.mean(ft.chroma_stft(y=y,sr=sr))\n",
    "# op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0     0.292520  0.019473        1567.592213         1884.101824  3277.399331   \n",
      "1     0.302334  0.023669        1891.507695         2064.112689  4235.807720   \n",
      "2     0.348398  0.020244        1533.034578         1912.124666  3618.361151   \n",
      "3     0.299812  0.015033        1157.071959         1460.133266  2096.174504   \n",
      "4     0.321138  0.023743        1227.748763         1635.783312  2557.649850   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
      "0            0.081148 -459.894409  115.394875  24.466005  19.742487  ...   \n",
      "1            0.100894 -399.525299  105.455101  32.384209  39.936787  ...   \n",
      "2            0.066713 -436.080231  117.834846  23.701845  33.740929  ...   \n",
      "3            0.061080 -465.447052  134.356430  25.707594  32.438938  ...   \n",
      "4            0.055948 -426.604523  132.837311  16.490423  40.396248  ...   \n",
      "\n",
      "      mfcc12     mfcc13    mfcc14    mfcc15     mfcc16    mfcc17    mfcc18  \\\n",
      "0  10.801866 -10.562201 -3.071242  6.419473 -14.149690  6.958096 -2.567645   \n",
      "1   3.762220  -4.576914 -4.536429  6.651690 -11.317846  1.959786 -5.086360   \n",
      "2   5.276185 -14.456746  3.779609  5.464593 -13.445355  6.153950 -1.745037   \n",
      "3   2.983900  -6.884625  2.211129  1.055087 -11.389618  5.357286 -2.765035   \n",
      "4   3.053195  -8.065528 -2.981065  4.453191  -9.022786  4.035585 -4.338405   \n",
      "\n",
      "     mfcc19    mfcc20  label  \n",
      "0  0.465186  1.926626      1  \n",
      "1  3.458086 -6.689055      1  \n",
      "2 -1.049948  0.514938      1  \n",
      "3 -2.005136 -1.127183      1  \n",
      "4  0.044551  3.631908      1  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "test.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0     0.303522  0.020837         881.430380         1412.443741  1344.888969   \n",
      "1     0.326297  0.063691         853.362134         1248.999047  1446.313477   \n",
      "2     0.276361  0.052355         976.811343         1391.618952  1730.332438   \n",
      "3     0.367084  0.074107        1017.253355         1530.821941  2089.842224   \n",
      "4     0.377733  0.054536        1072.264189         1479.197539  2122.920496   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
      "0            0.037060 -500.263123  120.719894  34.801353  15.563766  ...   \n",
      "1            0.035608 -406.130890  100.768730  29.579929  25.225727  ...   \n",
      "2            0.044009 -424.731171  104.934151  24.750797  28.922031  ...   \n",
      "3            0.031947 -389.379486   97.587769  37.843288  24.649574  ...   \n",
      "4            0.047062 -413.163422  118.297173  43.638687  28.899155  ...   \n",
      "\n",
      "     mfcc12     mfcc13    mfcc14    mfcc15     mfcc16    mfcc17     mfcc18  \\\n",
      "0 -8.680011 -10.652773  4.257936 -2.673468  -5.339294 -4.728747 -11.883916   \n",
      "1 -4.818441  -5.517306  0.380459 -1.863319  -5.007057  2.042716  -3.783194   \n",
      "2 -7.681666  -5.092205 -8.647792 -2.566745 -14.959568 -8.671085  -2.598978   \n",
      "3 -3.638850  -3.611868 -4.889376 -0.055150  -5.917768 -3.964338  -4.293300   \n",
      "4 -5.969706  -5.363680 -9.345110 -3.854643  -5.729967 -4.596859  -1.925599   \n",
      "\n",
      "     mfcc19    mfcc20  label  \n",
      "0 -3.114315 -7.775725      0  \n",
      "1 -6.155053 -8.967171      0  \n",
      "2 -1.995106 -3.859689      0  \n",
      "3 -4.035175 -3.591463      0  \n",
      "4 -3.927056 -4.853490      0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_23648\\1104326005.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(csvFileName, error_bad_lines=False)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_23648\\1104326005.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(csvFileName, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresponding number\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName, error_bad_lines=False)\n",
    "    # data['number'] = data['filename'].str[:1]\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    # data = data.drop(['label'],axis=1)\n",
    "    # data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "# moreTrainData = preProcessData(MORE_TRAIN_CSV_FILE)\n",
    "# moreTestData = preProcessData(MORE_TEST_CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "\n",
    "The model will be trained to predict the spoken digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPbfaLTrap87"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (256,)\n",
      "Y from validation data: (64,)\n",
      "Y from test data: (160,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [],
   "source": [
    "# #Normalizing the dataset\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform( X_train )\n",
    "# X_val = scaler.transform( X_val )\n",
    "# X_test = scaler.transform( X_test )\n",
    "\n",
    "# print(\"X from training data\", X_train.shape)\n",
    "# print(\"X from validation data\", X_val.shape)\n",
    "# print(\"X from test data\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.5781\n"
     ]
    }
   ],
   "source": [
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.7969\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C=10000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.7500\n",
      "Accuracy on training set: 0.773\n",
      "Accuracy on test set: 0.750\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "linear_svc=SVC(kernel='poly', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "linear_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=linear_svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred_test)))\n",
    "print(\"Accuracy on training set: {:.3f}\".format(linear_svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(linear_svc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forests\n",
      "Accuracy on training set: 0.977\n",
      "Accuracy on test set: 0.734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "print(\"\\nRandom Forests\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(forest ,open('../trainedModel.sav' , 'wb'))\n",
    "model= pickle.load(open('../trainedModel.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=1).fit(X_train, y_train)\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_val, y_val)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
