{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, the WAV files will be read and their features will be saved in the CSV files\n",
    "# As this is the most time consuming task, only enable it if you don't have the CSV files yet\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "MORE_TRAIN_CSV_FILE = \"more_train.csv\"\n",
    "MORE_TEST_CSV_FILE = \"more_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder recordings/close will be saved to train.csv\n",
      "The features of the files in the folder recordings1/open will be saved to train.csv\n",
      "The features of the files in the folder recordings1/close will be saved to train.csv\n",
      "The features of the files in the folder recordings/open will be saved to train.csv\n",
      "CSV files are created\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "import chromaFeatures \n",
    "import librosa.display\n",
    "if(os.path.exists(TRAIN_CSV_FILE) and os.path.isfile(TRAIN_CSV_FILE)):\n",
    "    os.remove(TRAIN_CSV_FILE)\n",
    "if(os.path.exists(TEST_CSV_FILE) and os.path.isfile(TEST_CSV_FILE)):\n",
    "    os.remove(TEST_CSV_FILE)\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName,label):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate '\n",
    "    # header = 'filename '\n",
    "    for i in range(1, 21):\n",
    "        header += f'mfcc{i} '\n",
    "    header += 'label '\n",
    "    header = header.split()\n",
    "    if not os.path.exists(csvFileName):\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    else:\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "    genres = '1 2 3 4 5 6 7 8 9 0'.split()\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        # chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_stft = chromaFeatures.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append+=f' {label}'\n",
    "        writer.writerow(to_append.split())\n",
    "        # writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"recordings/close\", TRAIN_CSV_FILE,1)\n",
    "    extractWavFeatures(\"recordings1/open\", TRAIN_CSV_FILE,0)\n",
    "    extractWavFeatures(\"recordings1/close\", TRAIN_CSV_FILE,1)\n",
    "    extractWavFeatures(\"recordings/open\", TRAIN_CSV_FILE,0)\n",
    "    # extractWavFeatures(\"recordings/others\", TRAIN_CSV_FILE,2)\n",
    "    # extractWavFeatures(\"recordings/open\", TEST_CSV_FILE,0)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melspec_mean_list=[]\n",
    "# melspec_var_list=[]\n",
    "# for i in range(1,16):\n",
    "#     y, sr = librosa.load(f'..\\\\data\\\\recordings\\\\Dina\\\\open\\\\h_open_({i}).wav', mono=True, duration=30)\n",
    "#     # this is the number of samples in a window per fft\n",
    "#     # n_fft = 2048\n",
    "#     # # The amount of samples we are shifting after each fft\n",
    "#     # hop_length = 512\n",
    "#     mel_signal = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "#     melspec_mean = np.mean(mel_signal)\n",
    "#     melspec_var = np.var(mel_signal)\n",
    "#     melspec_mean_list.append(melspec_mean)\n",
    "#     melspec_var_list.append(melspec_var)\n",
    "#     # print(f'mean{i}:{melspec_mean}')\n",
    "#     # print(f'var{i}:{melspec_var}')\n",
    "#     # spectrogram = np.abs(mel_signal)\n",
    "#     # power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "#     # librosa.display.specshow(power_to_db, sr=sr, x_axis='time', y_axis='mel', cmap='magma', hop_length=hop_length)\n",
    "# print(f'mean_max{max(melspec_mean_list)},mean_min:{min(melspec_mean_list)},mean_mean{np.mean(melspec_mean_list)}')\n",
    "# print(f'var_max{max(melspec_var_list)},var_min:{min(melspec_var_list)},var_mean{np.mean(melspec_var_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # melspec_mean_list=[]\n",
    "# # melspec_var_list=[]\n",
    "# # for i in range(1,16):\n",
    "# y, sr = librosa.load(f'..\\\\data\\\\recordings\\\\Mariam\\\\close\\\\b_close_(1).wav', mono=True, duration=30)\n",
    "# # this is the number of samples in a window per fft\n",
    "# # n_fft = 2048\n",
    "# # # The amount of samples we are shifting after each fft\n",
    "# # hop_length = 512\n",
    "# mel_signal = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "# melspec_mean = np.mean(mel_signal)\n",
    "# melspec_var = np.var(mel_signal)\n",
    "# melspec_mean_list.append(melspec_mean)\n",
    "# melspec_var_list.append(melspec_var)\n",
    "# # print(f'mean{i}:{melspec_mean}')\n",
    "# # print(f'var{i}:{melspec_var}')\n",
    "# spectrogram = np.abs(mel_signal)\n",
    "# power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "# librosa.display.specshow(power_to_db, sr=sr, x_axis='time', y_axis='mel', cmap='magma', hop_length=hop_length)\n",
    "# # print(f'mean_max{max(melspec_mean_list)},mean_min:{min(melspec_mean_list)},mean_mean{np.mean(melspec_mean_list)}')\n",
    "# # print(f'var_max{max(melspec_var_list)},var_min:{min(melspec_var_list)},var_mean{np.mean(melspec_var_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, sr = librosa.load('..\\\\recordings\\\\test\\\\close(13).wav', mono=True, duration=30)\n",
    "# mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "# mfcc\n",
    "# mfcc_list=[]\n",
    "# for e in mfcc:\n",
    "#             mfcc_list.append(e)\n",
    "# print(len(mfcc_list))\n",
    "# print(mfcc_list)\n",
    "# # mfcc.shape\n",
    "\n",
    "\n",
    "\n",
    "# import freature_ex as ex\n",
    "\n",
    "# mfcc=ex.get_mfcc(y,sr)\n",
    "# mfcc_list=[]\n",
    "# for e in mfcc:\n",
    "#             mfcc_list.append(e)\n",
    "# print(len(mfcc_list))\n",
    "# print(mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, sr = librosa.load('..\\\\recordings\\\\test\\\\close(13).wav', mono=True, duration=30)\n",
    "# op=np.mean(librosa.feature.chroma_stft(y=y,sr=sr))\n",
    "# op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromaFeatures as ft \n",
    "# op= np.mean(ft.chroma_stft(y=y,sr=sr))\n",
    "# op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0     0.233211  0.060876        1980.499957         2307.433957  4949.485518   \n",
      "1     0.285432  0.035748        1823.559789         2154.511190  4440.733754   \n",
      "2     0.278946  0.048961        1876.957824         2283.669924  5114.660942   \n",
      "3     0.263745  0.055076        1800.239710         2194.800112  4725.581055   \n",
      "4     0.246478  0.058140        1536.114708         2002.493192  3721.329013   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
      "0            0.074790 -326.950043  112.391731  24.532602  -7.646422  ...   \n",
      "1            0.074962 -384.217377  113.313568  24.379700  -2.288423  ...   \n",
      "2            0.078232 -328.949310  120.625397  11.633698 -10.470407  ...   \n",
      "3            0.072797 -316.711884  127.934776  23.606880 -16.524025  ...   \n",
      "4            0.057684 -324.862000  134.351212  20.889097 -10.809068  ...   \n",
      "\n",
      "      mfcc12     mfcc13     mfcc14    mfcc15     mfcc16    mfcc17    mfcc18  \\\n",
      "0   7.952314 -10.565011  -6.944203  5.085997 -13.903187 -0.266340 -4.229555   \n",
      "1   8.341515 -16.929974  -2.476463  4.832168 -16.396696  4.398739 -7.231216   \n",
      "2  10.960413 -14.327727  -6.141396  7.818789 -15.787643  0.682730 -3.464832   \n",
      "3   5.217277  -6.102111 -13.274597  8.084807 -10.662268 -5.263296 -5.466926   \n",
      "4   3.119925 -11.225745 -13.037125  3.837207  -7.006052 -6.191529 -1.797860   \n",
      "\n",
      "     mfcc19    mfcc20  label  \n",
      "0 -8.815009 -2.462990      1  \n",
      "1 -2.546654  0.542893      1  \n",
      "2 -2.835633  1.768572      1  \n",
      "3 -3.096693 -1.117827      1  \n",
      "4  0.541010 -3.945453      1  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30432\\3181961187.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(csvFileName, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresponding number\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName, error_bad_lines=False)\n",
    "    # data['number'] = data['filename'].str[:1]\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    # data = data.drop(['label'],axis=1)\n",
    "    # data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "# testData = preProcessData(TEST_CSV_FILE)\n",
    "# moreTrainData = preProcessData(MORE_TRAIN_CSV_FILE)\n",
    "# moreTestData = preProcessData(MORE_TEST_CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "\n",
    "The model will be trained to predict the spoken digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPbfaLTrap87"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (128,)\n",
      "Y from validation data: (32,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "# y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "# print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [],
   "source": [
    "# #Normalizing the dataset\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform( X_train )\n",
    "# X_val = scaler.transform( X_val )\n",
    "# X_test = scaler.transform( X_test )\n",
    "\n",
    "# print(\"X from training data\", X_train.shape)\n",
    "# print(\"X from validation data\", X_val.shape)\n",
    "# print(\"X from test data\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.8125\n"
     ]
    }
   ],
   "source": [
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.9688\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C=10000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.8750\n",
      "Accuracy on training set: 0.797\n",
      "Accuracy on test set: 0.875\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "poly_svc=SVC(kernel='poly', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "poly_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=poly_svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred_test)))\n",
    "print(\"Accuracy on training set: {:.3f}\".format(poly_svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(poly_svc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forests\n",
      "Accuracy on training set: 0.977\n",
      "Accuracy on test set: 0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "print(\"\\nRandom Forests\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWavFeatures():\n",
    "    list_of_features=[]\n",
    "    y, sr = librosa.load('../audio/audio.wav', mono=True, duration=30)\n",
    "    # remove leading and trailing silence\n",
    "    y, index = librosa.effects.trim(y)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    list_of_features.append(np.mean(chroma_stft))\n",
    "    list_of_features.append(np.mean(rmse))\n",
    "    list_of_features.append(np.mean(spec_cent))\n",
    "    list_of_features.append(np.mean(spec_bw))\n",
    "    list_of_features.append(np.mean(rolloff))\n",
    "    list_of_features.append(np.mean(zcr))\n",
    "\n",
    "    for e in mfcc:\n",
    "            list_of_features.append(np.mean(e))\n",
    "    \n",
    "    return(list_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_features=[]\n",
    "speech_features.append(extractWavFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.predict(speech_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(speech_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=1).fit(X_train, y_train)\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(tree ,open('../trainedModel.sav' , 'wb'))\n",
    "model= pickle.load(open('../trainedModel.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[ 0  0  6 10]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm=GaussianMixture(n_components=5)\n",
    "gmm.fit(X_train,y_train)\n",
    "ygmm_pred_class = gmm.predict(X_val)\n",
    "print(accuracy_score(y_val, ygmm_pred_class))\n",
    "print(confusion_matrix(y_val, ygmm_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.9062\n",
      "Accuracy on training set: 0.867\n",
      "Accuracy on test set: 0.906\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "rbf_svc=SVC(kernel='rbf', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "rbf_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=rbf_svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred_test)))\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rbf_svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rbf_svc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "def extractWavFeatures():\n",
    "    list_of_features=[]\n",
    "    y, sr = librosa.load('../audio/audio.wav', mono=True, duration=30)\n",
    "    # remove leading and trailing silence\n",
    "    y, index = librosa.effects.trim(y)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    list_of_features.append(np.mean(chroma_stft))\n",
    "    list_of_features.append(np.mean(rmse))\n",
    "    list_of_features.append(np.mean(spec_cent))\n",
    "    list_of_features.append(np.mean(spec_bw))\n",
    "    list_of_features.append(np.mean(rolloff))\n",
    "    list_of_features.append(np.mean(zcr))\n",
    "\n",
    "    for e in mfcc:\n",
    "            list_of_features.append(np.mean(e))\n",
    "    \n",
    "    return(list_of_features)\n",
    "speech_features=[]\n",
    "speech_features.append(extractWavFeatures())\n",
    "print(forest.predict(speech_features))\n",
    "print(svc.predict(speech_features))\n",
    "print(tree.predict(speech_features))\n",
    "print(poly_svc.predict(speech_features))\n",
    "print(rbf_svc.predict(speech_features))\n",
    "# print(gmm.predict(speech_features))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
