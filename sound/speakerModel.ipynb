{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, the WAV files will be read and their features will be saved in the CSV files\n",
    "# As this is the most time consuming task, only enable it if you don't have the CSV files yet\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "MORE_TRAIN_CSV_FILE = \"more_train.csv\"\n",
    "MORE_TEST_CSV_FILE = \"more_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder dataset2/Dina will be saved to train.csv\n",
      "The features of the files in the folder dataset2/Kareeman will be saved to train.csv\n",
      "The features of the files in the folder dataset2/Mariam will be saved to train.csv\n",
      "The features of the files in the folder dataset2/Nada will be saved to train.csv\n",
      "The features of the files in the folder dataset2/others will be saved to train.csv\n",
      "The features of the files in the folder dataset2/test will be saved to test.csv\n",
      "CSV files are created\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "import librosa.display\n",
    "if(os.path.exists(TRAIN_CSV_FILE) and os.path.isfile(TRAIN_CSV_FILE)):\n",
    "    os.remove(TRAIN_CSV_FILE)\n",
    "if(os.path.exists(TEST_CSV_FILE) and os.path.isfile(TEST_CSV_FILE)):\n",
    "    os.remove(TEST_CSV_FILE)\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName,label):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate '\n",
    "    # header = 'filename '\n",
    "    for i in range(1, 21):\n",
    "        header += f'mfcc{i} '\n",
    "    header += 'label '\n",
    "    header = header.split()\n",
    "    if not os.path.exists(csvFileName):\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    else:\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append+=f' {label}'\n",
    "        writer.writerow(to_append.split())\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"dataset2/Dina\", TRAIN_CSV_FILE,0)\n",
    "    extractWavFeatures(\"dataset2/Kareeman\", TRAIN_CSV_FILE,1)\n",
    "    extractWavFeatures(\"dataset2/Mariam\", TRAIN_CSV_FILE,2)\n",
    "    extractWavFeatures(\"dataset2/Nada\", TRAIN_CSV_FILE,3)\n",
    "    extractWavFeatures(\"dataset2/others\", TRAIN_CSV_FILE,4)\n",
    "    extractWavFeatures(\"dataset2/test\", TEST_CSV_FILE,0)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0     0.315417  0.042465        1164.384818         1423.455020  2393.137680   \n",
      "1     0.294068  0.054845        1228.853812         1514.037504  2405.984364   \n",
      "2     0.277608  0.047859        1295.236308         1618.044875  2674.067523   \n",
      "3     0.285265  0.043748        1121.270245         1367.419572  2222.114702   \n",
      "4     0.280511  0.039898        1251.483286         1576.828595  2678.325389   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
      "0            0.052868 -389.890411  150.855774  11.183009  22.068670  ...   \n",
      "1            0.053414 -345.394775  129.519958  13.182385  21.692543  ...   \n",
      "2            0.056149 -383.368439  117.782349  17.631424  22.915812  ...   \n",
      "3            0.052430 -384.875732  137.560730  18.019766  20.900148  ...   \n",
      "4            0.048354 -391.633545  138.709213  21.949665  27.736458  ...   \n",
      "\n",
      "      mfcc12     mfcc13    mfcc14    mfcc15     mfcc16    mfcc17    mfcc18  \\\n",
      "0 -12.073881 -14.054572  5.532455 -3.081187  -6.651666  3.730007 -1.473931   \n",
      "1  -5.131420 -15.347751  1.798121 -5.162611 -18.269531  4.172799 -4.176893   \n",
      "2  -5.422243 -13.708606  0.817735 -4.506720 -11.722920  0.953648 -4.063796   \n",
      "3 -12.955532 -13.693357  4.051044 -4.219286 -10.083455  7.517425 -0.438235   \n",
      "4  -1.318365 -13.930960  0.106095 -6.271118 -12.769134  3.758454 -8.122332   \n",
      "\n",
      "     mfcc19    mfcc20  label  \n",
      "0 -3.522629 -3.961222      0  \n",
      "1  2.479101  0.278954      0  \n",
      "2 -0.623660 -0.685452      0  \n",
      "3 -1.998429 -1.346377      0  \n",
      "4 -1.424410 -0.882042      0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "test.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0     0.385499  0.042646        3094.728230         2814.899700  6554.310367   \n",
      "1     0.424744  0.031093        2633.830703         2750.666181  5893.398438   \n",
      "2     0.422436  0.018715        3010.364208         2949.010562  6495.725855   \n",
      "3     0.315414  0.103497        2909.409124         2711.818530  5598.872070   \n",
      "4     0.426268  0.066927        2472.554845         2721.168070  5588.574540   \n",
      "\n",
      "   zero_crossing_rate       mfcc1      mfcc2      mfcc3      mfcc4  ...  \\\n",
      "0            0.151046 -337.948303  58.967972  -6.561305  20.965542  ...   \n",
      "1            0.119287 -463.290405  71.478134  33.924953  13.543034  ...   \n",
      "2            0.125006 -494.186279  59.766304  23.216095  21.660404  ...   \n",
      "3            0.177203 -258.590851  96.075989   6.182626  -3.788567  ...   \n",
      "4            0.108231 -225.651215  91.108780  -6.634482   6.556993  ...   \n",
      "\n",
      "     mfcc12     mfcc13    mfcc14     mfcc15    mfcc16    mfcc17    mfcc18  \\\n",
      "0 -7.341359 -18.928514  7.914616 -18.223011 -5.974346 -7.398223 -4.600142   \n",
      "1  2.291252  -4.547214  1.429956  -2.413893 -1.048685 -5.413887 -2.403088   \n",
      "2  0.937182  -6.168635 -4.257356  -2.636119 -7.921491 -9.741642 -1.514260   \n",
      "3 -6.151858 -10.551094 -0.230932  -7.791090 -4.841537 -4.292967  0.497894   \n",
      "4 -3.984868 -10.952374 -2.829420 -11.717101 -3.927502 -5.478830  3.909970   \n",
      "\n",
      "      mfcc19    mfcc20  label  \n",
      "0  -3.112499  0.163304      0  \n",
      "1  -8.021042 -4.447859      0  \n",
      "2  -7.291065 -3.577242      0  \n",
      "3 -16.506817 -1.024626      0  \n",
      "4 -13.017945 -0.121196      0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_28560\\1104326005.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(csvFileName, error_bad_lines=False)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_28560\\1104326005.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(csvFileName, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresponding number\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName, error_bad_lines=False)\n",
    "    # data['number'] = data['filename'].str[:1]\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    # data = data.drop(['label'],axis=1)\n",
    "    # data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "# moreTrainData = preProcessData(MORE_TRAIN_CSV_FILE)\n",
    "# moreTestData = preProcessData(MORE_TEST_CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "\n",
    "The model will be trained to predict the spoken digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPbfaLTrap87"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (283,)\n",
      "Y from validation data: (71,)\n",
      "Y from test data: (11,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [],
   "source": [
    "# #Normalizing the dataset\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform( X_train )\n",
    "# X_val = scaler.transform( X_val )\n",
    "# X_test = scaler.transform( X_test )\n",
    "\n",
    "# print(\"X from training data\", X_train.shape)\n",
    "# print(\"X from validation data\", X_val.shape)\n",
    "# print(\"X from test data\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(X_train).set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.3099\n"
     ]
    }
   ],
   "source": [
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.9014\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C=10000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.9155\n",
      "Accuracy on training set: 0.922\n",
      "Accuracy on test set: 0.915\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "poly_svc=SVC(kernel='poly', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "poly_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=poly_svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred_test)))\n",
    "print(\"Accuracy on training set: {:.3f}\".format(poly_svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(poly_svc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forests\n",
      "Accuracy on training set: 0.979\n",
      "Accuracy on test set: 0.831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "print(\"\\nRandom Forests\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(forest ,open('../trained_speaker_model.sav' , 'wb'))\n",
    "model= pickle.load(open('../trained_speaker_model.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=1).fit(X_train, y_train)\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "def extractWavFeatures():\n",
    "    list_of_features=[]\n",
    "    y, sr = librosa.load('dataset2/Kareeman/Recording(9).wav', mono=True, duration=30)\n",
    "    # remove leading and trailing silence\n",
    "    y, index = librosa.effects.trim(y)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    list_of_features.append(np.mean(chroma_stft))\n",
    "    list_of_features.append(np.mean(rmse))\n",
    "    list_of_features.append(np.mean(spec_cent))\n",
    "    list_of_features.append(np.mean(spec_bw))\n",
    "    list_of_features.append(np.mean(rolloff))\n",
    "    list_of_features.append(np.mean(zcr))\n",
    "\n",
    "    for e in mfcc:\n",
    "            list_of_features.append(np.mean(e))\n",
    "    \n",
    "    return(list_of_features)\n",
    "speech_features=[]\n",
    "speech_features.append(extractWavFeatures())\n",
    "print(forest.predict(speech_features))\n",
    "print(svc.predict(speech_features))\n",
    "print(tree.predict(speech_features))\n",
    "print(poly_svc.predict(speech_features))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
