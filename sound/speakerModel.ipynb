{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, the WAV files will be read and their features will be saved in the CSV files\n",
    "# As this is the most time consuming task, only enable it if you don't have the CSV files yet\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "MORE_TRAIN_CSV_FILE = \"more_train.csv\"\n",
    "MORE_TEST_CSV_FILE = \"more_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "import librosa.display\n",
    "if(os.path.exists(TRAIN_CSV_FILE) and os.path.isfile(TRAIN_CSV_FILE)):\n",
    "    os.remove(TRAIN_CSV_FILE)\n",
    "if(os.path.exists(TEST_CSV_FILE) and os.path.isfile(TEST_CSV_FILE)):\n",
    "    os.remove(TEST_CSV_FILE)\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName,label):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename '\n",
    "    # header = 'filename '\n",
    "    for i in range(1, 13):\n",
    "        header += f'chroma{i} '\n",
    "    for i in range(1, 129):\n",
    "        header += f'mel{i} '\n",
    "    for i in range(1, 8):\n",
    "        header += f'contrast{i} '\n",
    "    for i in range(1, 7):\n",
    "        header += f'tonnetz{i} '\n",
    "    for i in range(1, 41):\n",
    "        header += f'mfcc{i} '\n",
    "    header += 'label '\n",
    "    header = header.split()\n",
    "    if not os.path.exists(csvFileName):\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    else:\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        X, sample_rate = librosa.load(number, mono=True, duration=30)\n",
    "        \n",
    "        # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "        # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "\n",
    "        # Computes a chromagram from a waveform or power spectrogram.\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # Computes a mel-scaled spectrogram.\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # Computes spectral contrast\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # Computes the tonal centroid features (tonnetz)\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "        sr=sample_rate).T,axis=0)\n",
    "\n",
    "\n",
    "        to_append = f'{filename}'\n",
    "        for e in chroma:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in mel:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in contrast:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in tonnetz:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in mfccs:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append+=f' {label}'\n",
    "        writer.writerow(to_append.split())\n",
    "        # writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"dataset2/Dina\", TRAIN_CSV_FILE,0)\n",
    "    extractWavFeatures(\"dataset2/Kareeman\", TRAIN_CSV_FILE,1)\n",
    "    extractWavFeatures(\"dataset2/Mariam\", TRAIN_CSV_FILE,2)\n",
    "    extractWavFeatures(\"dataset2/Nada\", TRAIN_CSV_FILE,3)\n",
    "    extractWavFeatures(\"dataset2/others\", TRAIN_CSV_FILE,4)\n",
    "    extractWavFeatures(\"dataset2/test\", TEST_CSV_FILE,0)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load(\"dataset2/Dina/h_close_(1).wav\", mono=True, duration=30)\n",
    "stft = np.abs(librosa.stft(X))\n",
    "\n",
    "# chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "# print(chroma)\n",
    "\n",
    "# mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "# mel.shape\n",
    "\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "mfccs.shape\n",
    "\n",
    "# contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "# contrast.shape\n",
    "\n",
    "\n",
    "tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),sr=sample_rate).T,axis=0)\n",
    "tonnetz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melspec_mean_list=[]\n",
    "# melspec_var_list=[]\n",
    "# for i in range(1,16):\n",
    "#     y, sr = librosa.load(f'..\\\\data\\\\recordings\\\\Dina\\\\open\\\\h_open_({i}).wav', mono=True, duration=30)\n",
    "#     # this is the number of samples in a window per fft\n",
    "#     # n_fft = 2048\n",
    "#     # # The amount of samples we are shifting after each fft\n",
    "#     # hop_length = 512\n",
    "#     mel_signal = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "#     melspec_mean = np.mean(mel_signal)\n",
    "#     melspec_var = np.var(mel_signal)\n",
    "#     melspec_mean_list.append(melspec_mean)\n",
    "#     melspec_var_list.append(melspec_var)\n",
    "#     # print(f'mean{i}:{melspec_mean}')\n",
    "#     # print(f'var{i}:{melspec_var}')\n",
    "#     # spectrogram = np.abs(mel_signal)\n",
    "#     # power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "#     # librosa.display.specshow(power_to_db, sr=sr, x_axis='time', y_axis='mel', cmap='magma', hop_length=hop_length)\n",
    "# print(f'mean_max{max(melspec_mean_list)},mean_min:{min(melspec_mean_list)},mean_mean{np.mean(melspec_mean_list)}')\n",
    "# print(f'var_max{max(melspec_var_list)},var_min:{min(melspec_var_list)},var_mean{np.mean(melspec_var_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # melspec_mean_list=[]\n",
    "# # melspec_var_list=[]\n",
    "# # for i in range(1,16):\n",
    "# y, sr = librosa.load(f'..\\\\data\\\\recordings\\\\Mariam\\\\close\\\\b_close_(1).wav', mono=True, duration=30)\n",
    "# # this is the number of samples in a window per fft\n",
    "# # n_fft = 2048\n",
    "# # # The amount of samples we are shifting after each fft\n",
    "# # hop_length = 512\n",
    "# mel_signal = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "# melspec_mean = np.mean(mel_signal)\n",
    "# melspec_var = np.var(mel_signal)\n",
    "# melspec_mean_list.append(melspec_mean)\n",
    "# melspec_var_list.append(melspec_var)\n",
    "# # print(f'mean{i}:{melspec_mean}')\n",
    "# # print(f'var{i}:{melspec_var}')\n",
    "# spectrogram = np.abs(mel_signal)\n",
    "# power_to_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "# librosa.display.specshow(power_to_db, sr=sr, x_axis='time', y_axis='mel', cmap='magma', hop_length=hop_length)\n",
    "# # print(f'mean_max{max(melspec_mean_list)},mean_min:{min(melspec_mean_list)},mean_mean{np.mean(melspec_mean_list)}')\n",
    "# # print(f'var_max{max(melspec_var_list)},var_min:{min(melspec_var_list)},var_mean{np.mean(melspec_var_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [],
   "source": [
    "#Reading a dataset and convert file name to corresponding number\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName, error_bad_lines=False)\n",
    "    # data['number'] = data['filename'].str[:1]\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    # data = data.drop(['label'],axis=1)\n",
    "    # data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "# moreTrainData = preProcessData(MORE_TRAIN_CSV_FILE)\n",
    "# moreTestData = preProcessData(MORE_TEST_CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "\n",
    "The model will be trained to predict the spoken digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPbfaLTrap87"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [],
   "source": [
    "# #Normalizing the dataset\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform( X_train )\n",
    "# X_val = scaler.transform( X_val )\n",
    "# X_test = scaler.transform( X_test )\n",
    "\n",
    "# print(\"X from training data\", X_train.shape)\n",
    "# print(\"X from validation data\", X_val.shape)\n",
    "# print(\"X from test data\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C=10000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.9730\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.973\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "poly_svc=SVC(kernel='poly', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "poly_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=poly_svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred_test)))\n",
    "print(\"Accuracy on training set: {:.3f}\".format(poly_svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(poly_svc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "print(\"\\nRandom Forests\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(poly_svc ,open('../trained_speaker_model.sav' , 'wb'))\n",
    "model= pickle.load(open('trainedModel.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=1).fit(X_train, y_train)\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_val, y_val)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
