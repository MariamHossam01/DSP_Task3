{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, the WAV files will be read and their features will be saved in the CSV files\n",
    "# As this is the most time consuming task, only enable it if you don't have the CSV files yet\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "MORE_TRAIN_CSV_FILE = \"more_train.csv\"\n",
    "MORE_TEST_CSV_FILE = \"more_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mfcc\n",
    "stft\n",
    "chroma.stft\n",
    "mel\n",
    "spectral \n",
    "tonnez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder dataset2/Dina will be saved to train.csv\n",
      "The features of the files in the folder dataset2/Kareeman will be saved to train.csv\n",
      "The features of the files in the folder dataset2/Mariam will be saved to train.csv\n",
      "The features of the files in the folder dataset2/Nada will be saved to train.csv\n",
      "The features of the files in the folder dataset1/Dina will be saved to train.csv\n",
      "The features of the files in the folder dataset1/Kareeman will be saved to train.csv\n",
      "The features of the files in the folder dataset1/Mariam will be saved to train.csv\n",
      "The features of the files in the folder dataset1/Nada will be saved to train.csv\n",
      "The features of the files in the folder dataset2/others will be saved to train.csv\n",
      "CSV files are created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "import librosa.display\n",
    "if(os.path.exists(TRAIN_CSV_FILE) and os.path.isfile(TRAIN_CSV_FILE)):\n",
    "    os.remove(TRAIN_CSV_FILE)\n",
    "if(os.path.exists(TEST_CSV_FILE) and os.path.isfile(TEST_CSV_FILE)):\n",
    "    os.remove(TEST_CSV_FILE)\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName,label):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename '\n",
    "    # header = 'filename '\n",
    "    for i in range(1, 13):\n",
    "        header += f'chroma{i} '\n",
    "    for i in range(1, 129):\n",
    "        header += f'mel{i} '\n",
    "    for i in range(1, 8):\n",
    "        header += f'contrast{i} '\n",
    "    for i in range(1, 7):\n",
    "        header += f'tonnetz{i} '\n",
    "    for i in range(1, 41):\n",
    "        header += f'mfcc{i} '\n",
    "    header += 'label '\n",
    "    header = header.split()\n",
    "    if not os.path.exists(csvFileName):\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    else:\n",
    "        file = open(csvFileName, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        X, sample_rate = librosa.load(number, mono=True, duration=2.5)\n",
    "        \n",
    "        # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "        # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "\n",
    "        # Computes a chromagram from a waveform or power spectrogram.\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # Computes a mel-scaled spectrogram.\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # Computes spectral contrast\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # Computes the tonal centroid features (tonnetz)\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "        sr=sample_rate).T,axis=0)\n",
    "\n",
    "\n",
    "        to_append = f'{filename}'\n",
    "        for e in chroma:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in mel:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in contrast:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in tonnetz:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        for e in mfccs:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append+=f' {label}'\n",
    "        writer.writerow(to_append.split())\n",
    "        # writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"dataset2/Dina\", TRAIN_CSV_FILE,0)\n",
    "    extractWavFeatures(\"dataset2/Kareeman\", TRAIN_CSV_FILE,1)\n",
    "    extractWavFeatures(\"dataset2/Mariam\", TRAIN_CSV_FILE,2)\n",
    "    extractWavFeatures(\"dataset2/Nada\", TRAIN_CSV_FILE,3)\n",
    "    extractWavFeatures(\"dataset1/Dina\", TRAIN_CSV_FILE,0)\n",
    "    extractWavFeatures(\"dataset1/Kareeman\", TRAIN_CSV_FILE,1)\n",
    "    extractWavFeatures(\"dataset1/Mariam\", TRAIN_CSV_FILE,2)\n",
    "    extractWavFeatures(\"dataset1/Nada\", TRAIN_CSV_FILE,3)\n",
    "    extractWavFeatures(\"dataset2/others\", TRAIN_CSV_FILE,4)\n",
    "    # extractWavFeatures(\"dataset2/test\", TEST_CSV_FILE,0)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "    chroma1   chroma2   chroma3   chroma4   chroma5   chroma6   chroma7  \\\n",
      "0  0.435208  0.444573  0.507232  0.493202  0.403009  0.323319  0.335864   \n",
      "1  0.558728  0.563941  0.495348  0.457669  0.405068  0.479695  0.518341   \n",
      "2  0.457078  0.491001  0.538831  0.476358  0.454127  0.356903  0.327614   \n",
      "3  0.482293  0.471162  0.500524  0.463510  0.415543  0.368639  0.385356   \n",
      "4  0.470483  0.463248  0.499932  0.471146  0.406375  0.356658  0.377193   \n",
      "\n",
      "    chroma8   chroma9  chroma10  ...    mfcc32    mfcc33    mfcc34    mfcc35  \\\n",
      "0  0.455849  0.493729  0.519837  ... -1.595734  4.662979 -0.072742  4.025115   \n",
      "1  0.496340  0.528902  0.617000  ... -2.818082  3.372691 -1.455287  1.969472   \n",
      "2  0.409163  0.427747  0.490952  ...  0.817995  2.196296 -0.189620  2.099922   \n",
      "3  0.503881  0.511764  0.581159  ...  0.331302  1.773823  1.733602  3.554198   \n",
      "4  0.485798  0.527508  0.539757  ...  0.124184  4.012275  3.699968  3.839281   \n",
      "\n",
      "     mfcc36    mfcc37    mfcc38    mfcc39    mfcc40  label  \n",
      "0  1.543129 -0.672678 -3.253962 -3.311791 -0.758835      0  \n",
      "1  2.190478  1.576735  0.507850 -1.781559 -0.952867      0  \n",
      "2  2.329488  1.043045 -1.302302 -3.226445 -0.718094      0  \n",
      "3  3.171555  0.772937 -4.130584 -3.316514 -0.311360      0  \n",
      "4  1.813057 -0.133443 -1.672536 -2.960680 -0.216386      0  \n",
      "\n",
      "[5 rows x 194 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresponding number\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName, error_bad_lines=False)\n",
    "    # data['number'] = data['filename'].str[:1]\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    # data = data.drop(['label'],axis=1)\n",
    "    # data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "# testData = preProcessData(TEST_CSV_FILE)\n",
    "# moreTrainData = preProcessData(MORE_TRAIN_CSV_FILE)\n",
    "# moreTestData = preProcessData(MORE_TEST_CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "\n",
    "The model will be trained to predict the spoken digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPbfaLTrap87"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (536,)\n",
      "Y from validation data: (134,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "# y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "# print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [],
   "source": [
    "# #Normalizing the dataset\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform( X_train )\n",
    "# X_val = scaler.transform( X_val )\n",
    "# X_test = scaler.transform( X_test )\n",
    "\n",
    "# print(\"X from training data\", X_train.shape)\n",
    "# print(\"X from validation data\", X_val.shape)\n",
    "# print(\"X from test data\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(X_train).set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.7090\n"
     ]
    }
   ],
   "source": [
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.9328\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C=10000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.9328\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.933\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "poly_svc=SVC(kernel='poly', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "poly_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=poly_svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred_test)))\n",
    "print(\"Accuracy on training set: {:.3f}\".format(poly_svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(poly_svc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.9328\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.933\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "rbf_svc=SVC(kernel='rbf', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "rbf_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=rbf_svc.predict(X_val)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_val, y_pred_test)))\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rbf_svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rbf_svc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forests\n",
      "Accuracy on training set: 0.991\n",
      "Accuracy on test set: 0.881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "print(\"\\nRandom Forests\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=1).fit(X_train, y_train)\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(forest ,open('../trained_speaker_model.sav' , 'wb'))\n",
    "model= pickle.load(open('../trained_speaker_model.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[4]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "def extractWavFeatures():\n",
    "    list_of_features=[]\n",
    "\n",
    "    X, sample_rate = librosa.load('../audio/audio.wav', mono=True, duration=2.5)\n",
    "    \n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # Computes a chromagram from a waveform or power spectrogram.\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes a mel-scaled spectrogram.\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes spectral contrast\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes the tonal centroid features (tonnetz)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "\n",
    "    for e in chroma:\n",
    "        list_of_features.append (np.mean(e))\n",
    "    for e in mel:\n",
    "        list_of_features.append (np.mean(e))\n",
    "    for e in contrast:\n",
    "        list_of_features.append (np.mean(e))\n",
    "    for e in tonnetz:\n",
    "        list_of_features.append (np.mean(e))\n",
    "    for e in mfccs:\n",
    "        list_of_features.append (np.mean(e))\n",
    "    \n",
    "    return(list_of_features)\n",
    "\n",
    "\n",
    "speech_features=[]\n",
    "\n",
    "speech_features.append(extractWavFeatures())\n",
    "print(forest.predict(speech_features))\n",
    "print(svc.predict(speech_features))\n",
    "print(tree.predict(speech_features))\n",
    "print(poly_svc.predict(speech_features))\n",
    "print(rbf_svc.predict(speech_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-510.5929,\n",
       " 88.87672,\n",
       " 31.873777,\n",
       " 17.811573,\n",
       " 3.0700498,\n",
       " 4.767426,\n",
       " -5.014845,\n",
       " -2.5228958,\n",
       " -7.2420354,\n",
       " 1.643732,\n",
       " -1.8049115,\n",
       " -7.4008164,\n",
       " -6.4478846,\n",
       " 3.066079,\n",
       " -2.176268,\n",
       " -4.572109,\n",
       " -6.106249,\n",
       " -8.015044,\n",
       " -2.8094447,\n",
       " -6.4979606,\n",
       " -1.7176459,\n",
       " -4.9890847,\n",
       " -0.52704436,\n",
       " 2.449116,\n",
       " 1.0694981,\n",
       " -0.5652438,\n",
       " 1.8900669,\n",
       " 1.4032432,\n",
       " -2.0896835,\n",
       " -1.0223411,\n",
       " -0.4114135,\n",
       " 4.6742864,\n",
       " 4.0699544,\n",
       " 4.6058636,\n",
       " 4.795103,\n",
       " 3.6240046,\n",
       " 1.9721831,\n",
       " 0.77030706,\n",
       " -0.7970575,\n",
       " 0.53832895]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "X, sample_rate = librosa.load('dataset1/Nada/Recording.wav', mono=True, duration=2.5)\n",
    "    \n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "list_of_features=[]\n",
    "for e in mfccs:\n",
    "        list_of_features.append (np.mean(e))\n",
    "list_of_features"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
